{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/tqdm_joblib/__init__.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm_joblib import tqdm_joblib\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Data Dictionary\n",
    "data_dict_path = '../../data/data_dictionary.xlsx'\n",
    "data_dictionary = pd.read_excel(data_dict_path)\n",
    "\n",
    "# Download Scoring File -- what the input data will be for the end\n",
    "scoring_path = '../../data/scoring.xlsx'\n",
    "scoring = pd.read_excel(scoring_path)\n",
    "\n",
    "# Download Submission Format -- what the format of the output should be from my model\n",
    "submission_format_path = '../../data/submission_format.csv'\n",
    "submission_format = pd.read_csv(submission_format_path)\n",
    "\n",
    "# Download Training Data -- what the training data is for this\n",
    "training_path = '../../data/training.xlsx'\n",
    "training = pd.read_excel(training_path).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linear_regression(X, y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    return model\n",
    "\n",
    "class ConstantModel:\n",
    "    # A fallback model that always predicts a constant value\n",
    "    def __init__(self, value):\n",
    "        self.value = value  # Store the constant target value\n",
    "\n",
    "    def predict(self, X):\n",
    "        #  mimic contant\n",
    "        if not hasattr(X, '__len__'):  # Ensure X has a length (is iterable)\n",
    "            return self.value  # Just return the value if X isn't iterable\n",
    "        return [self.value] * len(X)  # Normal case\n",
    "\n",
    "def fit_catboost(X, y):\n",
    "    try:\n",
    "        model = CatBoostRegressor(\n",
    "            iterations=100,\n",
    "            learning_rate=0.05,\n",
    "            depth=6,\n",
    "            cat_features=list(X.columns),\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        model.fit(X, y)\n",
    "\n",
    "        return model\n",
    "    except:\n",
    "        singular_value = y.iloc[0] if hasattr(y, 'iloc') else y[0]  # Extract the constant target value\n",
    "\n",
    "        return ConstantModel(singular_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_data = training.copy()\n",
    "car_data['Model Year'] = car_data['Model Year'].astype(str)\n",
    "\n",
    "categorical_cols = car_data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "encoded_car_data =  pd.get_dummies(car_data, columns=categorical_cols)\n",
    "\n",
    "train_indices = car_data.sample(frac=0.8, random_state=0).index\n",
    "test_indices = car_data.drop(train_indices).index\n",
    "\n",
    "train = car_data.loc[train_indices].copy()\n",
    "test = car_data.loc[test_indices].copy()\n",
    "\n",
    "train_encoded = encoded_car_data.loc[train_indices].copy()\n",
    "test_encoded = encoded_car_data.loc[test_indices].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_by_basis(train_data, train_encoded, basis_columns, prediction_columns, target_col, model_func, encode):\n",
    "\n",
    "    # Define the columns used to create different models\n",
    "    basis_values = [train_data[col].unique().tolist() for col in basis_columns] # these are the potential values for each basis\n",
    "\n",
    "    # Generate all possible (Model Year, Fuel Type) combinations as tuples\n",
    "    basis_combinations = [tuple(values) for values in product(*basis_values)] # these are the combos of basis's so like 2020 Electric for example\n",
    "\n",
    "    # Dictionary to store trained models, using (Model Year, Fuel Type) as the key\n",
    "    trained_models = {}\n",
    "    for basis_key in basis_combinations:\n",
    "\n",
    "        basis_dict = {col: value for col, value in zip(basis_columns, basis_key)}\n",
    "        # Filter training data for the specific Model Year & Fuel Type\n",
    "        basis_indices = train_data[\n",
    "            train_data[basis_dict.keys()].eq(pd.Series(basis_dict)).all(axis=1)\n",
    "        ].index \n",
    "\n",
    "        # check if encoded\n",
    "        model_data = train_encoded.copy() if encode else train_data.copy()\n",
    "\n",
    "        # initialize X and y\n",
    "        X = model_data.loc[basis_indices, prediction_columns]\n",
    "        y = model_data.loc[basis_indices][target_col]\n",
    "\n",
    "\n",
    "        if len(X) > 10: # if there are at least 25 values\n",
    "            model = model_func(X, y)\n",
    "            safe = True\n",
    "        else:\n",
    "            model = model_func(model_data[prediction_columns], model_data[target_col])\n",
    "            safe = False\n",
    "\n",
    "        # Store trained model using the (Model Year, Fuel Type) tuple as the key\n",
    "        trained_models[basis_key] = (model, safe)\n",
    "\n",
    "    return trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(car_data, encoded_car_data, trained_models, basis_columns, prediction_columns, target_col, encode):\n",
    "    all_prediction_rows = []\n",
    "    for test_idx in test_indices:\n",
    "\n",
    "        row = car_data.loc[test_idx]\n",
    "\n",
    "        # get the basis values in the row (like 2020 for Model Year if Model Year is a basis)\n",
    "        model_basis_dict = {col: row[col] for col in basis_columns}\n",
    "\n",
    "        # get the model based on the basis\n",
    "        model, safe = trained_models[tuple(model_basis_dict.values())]\n",
    "\n",
    "        # get the encoded row\n",
    "        if encode:\n",
    "            formatted_row = encoded_car_data.loc[test_idx]\n",
    "            formatted_row = formatted_row[prediction_columns]\n",
    "        else:\n",
    "            formatted_row = row[prediction_columns]\n",
    "\n",
    "        # get the prediction vs. actual\n",
    "        prediction = model.predict(pd.DataFrame(formatted_row).T)[0]\n",
    "        actual = test.loc[test_idx, target_col]\n",
    "\n",
    "        prediction_row = pd.DataFrame({\n",
    "            'index': [test_idx],\n",
    "            'prediction': [round(prediction, 0)],\n",
    "            'actual': [actual],\n",
    "            'safe': [safe]\n",
    "        })\n",
    "        all_prediction_rows.append(prediction_row)\n",
    "\n",
    "    prediction_df = pd.concat(all_prediction_rows)\n",
    "    rmse = np.sqrt(mean_squared_error(prediction_df['actual'], prediction_df['prediction']))\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get the combinations of basis columns and prediction columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_options = list(set(train.columns) - {'Date', 'Vehicle Population'})\n",
    "\n",
    "basis_prediction_combos = []\n",
    "for _ in range(1000):\n",
    "    # Select 1-3 random basis columns\n",
    "    basis_columns = random.sample(column_options, random.randint(1, 3))\n",
    "    \n",
    "    # Select 3-7 prediction columns that are **not in basis_columns**\n",
    "    remaining_columns = list(set(column_options) - set(basis_columns))\n",
    "    prediction_columns = random.sample(remaining_columns, random.randint(3, 8-len(basis_columns)))\n",
    "    \n",
    "    # Store as a tuple\n",
    "    basis_prediction_combos.append((basis_columns, prediction_columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Run the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Models:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3124c2e9089a429db4b382d5b3915bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping already processed: ['Number of Vehicles Registered at the Same Address'], ['Fuel Type', 'Region', 'Model Year', 'Vehicle Category', 'Electric Mile Range']\n",
      "Skipping already processed: ['Fuel Type', 'Fuel Technology'], ['GVWR Class', 'Electric Mile Range', 'Region', 'Vehicle Category', 'Model Year', 'Number of Vehicles Registered at the Same Address']\n",
      "Skipping already processed: ['Fuel Technology', 'Vehicle Category', 'Region'], ['Model Year', 'Electric Mile Range', 'Fuel Type']\n",
      "Skipping already processed: ['Model Year'], ['GVWR Class', 'Fuel Type', 'Fuel Technology', 'Electric Mile Range', 'Number of Vehicles Registered at the Same Address', 'Region']\n",
      "Skipping already processed: ['Vehicle Category', 'Number of Vehicles Registered at the Same Address'], ['GVWR Class', 'Fuel Type', 'Region']\n",
      "Skipping already processed: ['GVWR Class', 'Number of Vehicles Registered at the Same Address', 'Fuel Type'], ['Electric Mile Range', 'Vehicle Category', 'Region']\n",
      "Skipping already processed: ['Region', 'Number of Vehicles Registered at the Same Address', 'Model Year'], ['Electric Mile Range', 'Fuel Type', 'GVWR Class']\n",
      "Skipping already processed: ['GVWR Class', 'Fuel Technology', 'Region'], ['Vehicle Category', 'Electric Mile Range', 'Model Year', 'Fuel Type']\n",
      "Skipping already processed: ['Model Year'], ['Number of Vehicles Registered at the Same Address', 'GVWR Class', 'Fuel Technology', 'Fuel Type']\n",
      "Skipping already processed: ['Fuel Type'], ['Number of Vehicles Registered at the Same Address', 'Fuel Technology', 'GVWR Class', 'Region', 'Model Year']\n",
      "Skipping already processed: ['Vehicle Category', 'Electric Mile Range'], ['Number of Vehicles Registered at the Same Address', 'GVWR Class', 'Fuel Type', 'Region', 'Model Year', 'Fuel Technology']\n",
      "Skipping already processed: ['Fuel Type', 'Number of Vehicles Registered at the Same Address'], ['Vehicle Category', 'Fuel Technology', 'Electric Mile Range']\n",
      "Skipping already processed: ['Electric Mile Range'], ['Fuel Type', 'Number of Vehicles Registered at the Same Address', 'GVWR Class', 'Fuel Technology', 'Vehicle Category', 'Model Year']\n",
      "Skipping already processed: ['Number of Vehicles Registered at the Same Address', 'Fuel Technology', 'Fuel Type'], ['Model Year', 'Vehicle Category', 'GVWR Class', 'Region', 'Electric Mile Range']\n",
      "Skipping already processed: ['Electric Mile Range'], ['Vehicle Category', 'Number of Vehicles Registered at the Same Address', 'Region', 'GVWR Class', 'Model Year']\n",
      "Skipping already processed: ['Number of Vehicles Registered at the Same Address'], ['Region', 'Fuel Type', 'GVWR Class']\n",
      "Skipping already processed: ['Region', 'Model Year', 'Number of Vehicles Registered at the Same Address'], ['GVWR Class', 'Vehicle Category', 'Electric Mile Range', 'Fuel Technology', 'Fuel Type']\n",
      "Skipping already processed: ['Region', 'Fuel Type', 'Fuel Technology'], ['Vehicle Category', 'Number of Vehicles Registered at the Same Address', 'Electric Mile Range']\n",
      "Skipping already processed: ['Fuel Type', 'Vehicle Category'], ['Electric Mile Range', 'Region', 'Fuel Technology', 'GVWR Class', 'Number of Vehicles Registered at the Same Address']\n",
      "Skipping already processed: ['Fuel Type'], ['GVWR Class', 'Region', 'Fuel Technology', 'Number of Vehicles Registered at the Same Address', 'Model Year', 'Electric Mile Range', 'Vehicle Category']\n",
      "Skipping already processed: ['Number of Vehicles Registered at the Same Address'], ['Vehicle Category', 'Fuel Type', 'GVWR Class', 'Region', 'Fuel Technology']\n",
      "Skipping already processed: ['Fuel Technology'], ['Vehicle Category', 'GVWR Class', 'Region', 'Electric Mile Range']\n",
      "Skipping already processed: ['Fuel Type', 'Region'], ['GVWR Class', 'Number of Vehicles Registered at the Same Address', 'Electric Mile Range', 'Vehicle Category', 'Model Year']\n",
      "Skipping already processed: ['GVWR Class', 'Fuel Technology'], ['Vehicle Category', 'Electric Mile Range', 'Fuel Type']\n",
      "Skipping already processed: ['Electric Mile Range'], ['Number of Vehicles Registered at the Same Address', 'GVWR Class', 'Fuel Technology', 'Vehicle Category', 'Region']\n",
      "Skipping already processed: ['Number of Vehicles Registered at the Same Address'], ['Fuel Technology', 'Fuel Type', 'Region', 'Electric Mile Range', 'Model Year', 'Vehicle Category']\n",
      "Skipping already processed: ['Model Year'], ['Region', 'Number of Vehicles Registered at the Same Address', 'Fuel Type']\n",
      "Skipping already processed: ['Number of Vehicles Registered at the Same Address', 'Fuel Technology'], ['Fuel Type', 'Electric Mile Range', 'Vehicle Category', 'Model Year']\n",
      "Skipping already processed: ['Fuel Technology', 'Electric Mile Range', 'Region'], ['Fuel Type', 'Model Year', 'Number of Vehicles Registered at the Same Address']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define function to process each set of columns\n",
    "model_func = fit_catboost\n",
    "encode = False\n",
    "\n",
    "# Define file path for saving results\n",
    "results_file = '../../results/catboost_optim.csv'\n",
    "\n",
    "# Load existing results if the file exists\n",
    "if os.path.exists(results_file):\n",
    "    model_results = pd.read_csv(results_file)\n",
    "else:\n",
    "    model_results = pd.DataFrame(columns=['basis_columns', 'prediction_columns', 'rmse'])\n",
    "\n",
    "# Convert existing basis-prediction combinations to a set for quick lookup\n",
    "existing_combos = set(zip(model_results['basis_columns'].astype(str), model_results['prediction_columns'].astype(str)))\n",
    "\n",
    "def process_basis_prediction_combo(basis_columns, prediction_columns):\n",
    "    target_col = 'Vehicle Population'\n",
    "    \n",
    "    # Convert combo to string format for checking existence\n",
    "    combo_key = (str(basis_columns), str(prediction_columns))\n",
    "    if combo_key in existing_combos:\n",
    "        print(f\"Skipping already processed: {basis_columns}, {prediction_columns}\")\n",
    "        return None  # Skip iteration\n",
    "    \n",
    "    # Ensure prediction columns do not include basis columns\n",
    "    if encode:\n",
    "        clean_prediction_columns = list(set(col for col in train_encoded.columns if col.split(\"_\")[0] not in basis_columns) - {target_col, 'Date'})\n",
    "    else:\n",
    "        clean_prediction_columns = prediction_columns\n",
    "    \n",
    "    # Train models and calculate RMSE\n",
    "    trained_models = get_models_by_basis(train, train_encoded, basis_columns, clean_prediction_columns, target_col, model_func, encode)\n",
    "    rmse = calculate_rmse(car_data, encoded_car_data, trained_models, basis_columns, clean_prediction_columns, target_col, encode)\n",
    "\n",
    "    # Create DataFrame for this iteration\n",
    "    result_df = pd.DataFrame({\n",
    "        'basis_columns': [basis_columns],\n",
    "        'prediction_columns': [prediction_columns],\n",
    "        'rmse': [rmse]\n",
    "    })\n",
    "\n",
    "    # Append results to CSV immediately\n",
    "    result_df.to_csv(results_file, index=False, mode='a', header=not os.path.exists(results_file))\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Run in parallel using tqdm_joblib\n",
    "with tqdm_joblib(tqdm(desc=\"Processing Models\", total=len(basis_prediction_combos))):\n",
    "    model_results_list = Parallel(n_jobs=-1)(\n",
    "        delayed(process_basis_prediction_combo)(basis, pred) for basis, pred in basis_prediction_combos\n",
    "    )\n",
    "\n",
    "# Remove `None` values from the list (skipped iterations)\n",
    "model_results_list = [df for df in model_results_list if df is not None]\n",
    "\n",
    "# Append all new results to the file\n",
    "if model_results_list:\n",
    "    model_results = pd.concat(model_results_list, ignore_index=True)\n",
    "    model_results.to_csv(results_file, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
